{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# Load the dataset and preprocess the images\n",
    "def load_dataset(image_size=256, batch_size=16, dataset_path='C:/Users/ASUS/Downloads/faces'):\n",
    "    def preprocess_image(image):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = (image / 127.5) - 1\n",
    "        return image\n",
    "\n",
    "    def load_image(image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [image_size, image_size])\n",
    "        image = preprocess_image(image)\n",
    "        return image\n",
    "\n",
    "    def random_crop(image):\n",
    "        cropped_image = tf.image.random_crop(image, size=[image_size, image_size, 3])\n",
    "        return cropped_image\n",
    "\n",
    "  # Load the dataset and apply random cropping\n",
    "    dataset = tf.data.Dataset.list_files(dataset_path + '/*.png')\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(random_crop, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generator_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Dense(7*7*256, use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Reshape((7, 7, 256))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "# # Define the generator and discriminator models\n",
    "# def generator_model(input_shape, n_residual_blocks=16):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "#     # First block: input to residual blocks\n",
    "#     x = tf.keras.layers.Dense(512)(inputs)\n",
    "#     x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "#     x = tf.keras.layers.Reshape((1, 1, 512))(x)\n",
    "\n",
    "#   # Residual blocks\n",
    "#     for i in range(n_residual_blocks):\n",
    "#         x = tf.keras.layers.Conv2D(512, 3, padding='same', use_bias=False)(x)\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "#         x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "#         x = tf.keras.layers.Conv2D(512, 3, padding='same', use_bias=False)(x)\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "#         x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "#         x = tf.keras.layers.Conv2D(256, 3, padding='same', use_bias=False)(x)\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "#         x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "#         # Output\n",
    "#         x = tf.keras.layers.Conv2D(3, 1, activation='tanh')(x)\n",
    "\n",
    "#         return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "\n",
    "def discriminator_model(input_shape):\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(64, 3, strides=2, padding='same')(inputs)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(512, 3, strides=2, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        # Output\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Define the training loop\n",
    "def train(dataset, latent_dim=128, epochs=50, sample_interval=50):\n",
    "    # Create the generator and discriminator models\n",
    "    generator = generator_model((latent_dim,))\n",
    "    discriminator = discriminator_model((256, 256, 3))\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_g = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "    optimizer_d = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "    # Loss functions\n",
    "    loss_fn_g = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    loss_fn_d = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch in dataset:\n",
    "            # Generate fake images\n",
    "            noise = tf.random.normal((batch.shape[0], latent_dim))\n",
    "            fake_images = generator(noise, training=True)\n",
    "            fake_images = tf.image.resize(fake_images, [256, 256])\n",
    "\n",
    "            # Concatenate real and fake images\n",
    "            real_and_fake = tf.concat([batch, fake_images], axis=0)\n",
    "\n",
    "            # Labels for real and fake images\n",
    "            labels_real = tf.ones((batch.shape[0], 1))\n",
    "            labels_fake = tf.zeros((batch.shape[0], 1))\n",
    "            labels = tf.concat([labels_real, labels_fake], axis=0)\n",
    "\n",
    "            # Train the discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = discriminator(real_and_fake, training=True)\n",
    "                loss_d = loss_fn_d(labels, logits)\n",
    "            grads = tape.gradient(loss_d, discriminator.trainable_variables)\n",
    "            optimizer_d.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "            # Train the generator\n",
    "            noise = tf.random.normal((batch.shape[0], latent_dim))\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = generator(noise, training=True)\n",
    "                fake_images = tf.image.resize(fake_images, [256, 256])\n",
    "                logits_fake = discriminator(fake_images, training=True)\n",
    "                loss_g = loss_fn_g(tf.ones_like(logits_fake), logits_fake)\n",
    "            grads = tape.gradient(loss_g, generator.trainable_variables)\n",
    "            optimizer_g.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "        # Print the progress\n",
    "        print(\"Time for epoch {} is {} sec\".format(epoch + 1, time.time() - start_time))\n",
    "\n",
    "        # Save generated images\n",
    "        if (epoch + 1) % sample_interval == 0:\n",
    "            noise = tf.random.normal((16, latent_dim))\n",
    "            generated_images = generator(noise, training=False)\n",
    "            for i in range(generated_images.shape[0]):\n",
    "                save_img('C:/Users/ASUS/Downloads/generated_' + str(i) + '.png', generated_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 10581.954968214035 sec\n",
      "Time for epoch 2 is 9581.514153718948 sec\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset \n",
    "dataset = load_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 9208.322114229202 sec\n",
      "Time for epoch 2 is 9290.493214845657 sec\n",
      "Time for epoch 3 is 9025.061330080032 sec\n",
      "Time for epoch 4 is 8755.84211730957 sec\n",
      "Time for epoch 5 is 8854.225080490112 sec\n",
      "Time for epoch 6 is 8779.539382696152 sec\n",
      "Time for epoch 7 is 8773.808583974838 sec\n",
      "Time for epoch 8 is 8787.269788742065 sec\n",
      "Time for epoch 9 is 8833.937662601471 sec\n",
      "Time for epoch 10 is 40082.33596634865 sec\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 26.325513124465942 sec\n",
      "Time for epoch 2 is 27.825599193572998 sec\n",
      "Time for epoch 3 is 28.306364059448242 sec\n",
      "Time for epoch 4 is 28.61549186706543 sec\n",
      "Time for epoch 5 is 29.49031710624695 sec\n",
      "Time for epoch 6 is 29.780969381332397 sec\n",
      "Time for epoch 7 is 30.82942795753479 sec\n",
      "Time for epoch 8 is 29.02382254600525 sec\n",
      "Time for epoch 9 is 29.379705667495728 sec\n",
      "Time for epoch 10 is 29.101566076278687 sec\n",
      "Time for epoch 11 is 29.461113691329956 sec\n",
      "Time for epoch 12 is 29.42032551765442 sec\n",
      "Time for epoch 13 is 30.247260093688965 sec\n",
      "Time for epoch 14 is 30.669936180114746 sec\n",
      "Time for epoch 15 is 31.875087022781372 sec\n",
      "Time for epoch 16 is 30.04021453857422 sec\n",
      "Time for epoch 17 is 28.960651636123657 sec\n",
      "Time for epoch 18 is 29.361088514328003 sec\n",
      "Time for epoch 19 is 29.603143453598022 sec\n",
      "Time for epoch 20 is 29.148345947265625 sec\n",
      "Time for epoch 21 is 29.843295335769653 sec\n",
      "Time for epoch 22 is 30.28518009185791 sec\n",
      "Time for epoch 23 is 31.34323525428772 sec\n",
      "Time for epoch 24 is 31.765979528427124 sec\n",
      "Time for epoch 25 is 29.12954592704773 sec\n",
      "Time for epoch 26 is 28.953335285186768 sec\n",
      "Time for epoch 27 is 29.6609365940094 sec\n",
      "Time for epoch 28 is 29.68863034248352 sec\n",
      "Time for epoch 29 is 30.006385326385498 sec\n",
      "Time for epoch 30 is 29.901216983795166 sec\n",
      "Time for epoch 31 is 31.28024911880493 sec\n",
      "Time for epoch 32 is 31.558868408203125 sec\n",
      "Time for epoch 33 is 32.7503399848938 sec\n",
      "Time for epoch 34 is 29.10699701309204 sec\n",
      "Time for epoch 35 is 29.635565757751465 sec\n",
      "Time for epoch 36 is 29.656879663467407 sec\n",
      "Time for epoch 37 is 30.14802575111389 sec\n",
      "Time for epoch 38 is 30.213967323303223 sec\n",
      "Time for epoch 39 is 30.58687663078308 sec\n",
      "Time for epoch 40 is 30.91081714630127 sec\n",
      "Time for epoch 41 is 32.26446747779846 sec\n",
      "Time for epoch 42 is 31.703819274902344 sec\n",
      "Time for epoch 43 is 29.441234588623047 sec\n",
      "Time for epoch 44 is 29.61560869216919 sec\n",
      "Time for epoch 45 is 30.27293086051941 sec\n",
      "Time for epoch 46 is 30.01142430305481 sec\n",
      "Time for epoch 47 is 31.20807695388794 sec\n",
      "Time for epoch 48 is 32.08082914352417 sec\n",
      "Time for epoch 49 is 32.35410404205322 sec\n",
      "Time for epoch 50 is 29.321226835250854 sec\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
